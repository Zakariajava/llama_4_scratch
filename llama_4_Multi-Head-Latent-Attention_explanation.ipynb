{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd1efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Head Latent Attention (MLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f06e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example toy embeddings (in reality they are much larger, >1000 dimensions):\n",
    "# 1. \"The\"     : [0.3, 0.2, 0.1]\n",
    "# 2. \"dog\"     : [0.5, 0.1, 0.3]\n",
    "# 3. \"ran\"     : [0.8, 0.4, 0.2]\n",
    "# 4. \"quickly\" : [0.2, 0.7, 0.1]\n",
    "# 5. \"around\"  : [0.2, 0.7, 0.1]\n",
    "# 6. \"the\"     : [0.3, 0.2, 0.1]\n",
    "#\n",
    "# Notes:\n",
    "# - In reality, embeddings have very large dimensions (hundreds or thousands).\n",
    "# - We don’t know exactly what each dimension represents.\n",
    "# - We just decide the size of the vector (embedding dimension).\n",
    "#\n",
    "# Key idea:\n",
    "# - Each embedding vector initially represents some notion of the word itself.\n",
    "#   Example: \"dog\" → [0.5, 0.1, 0.3]\n",
    "# - But we want these vectors to capture not only the word,\n",
    "#   but also the CONTEXT in which the word appears.\n",
    "#\n",
    "# Example with context:\n",
    "# - The embedding for \"ran\" should encode that \"ran\" refers to the \"dog\".\n",
    "# - Importantly, we should NOT include information about future words\n",
    "#   (because the model’s job is to predict them).\n",
    "#\n",
    "# Prediction process:\n",
    "# - The model does not predict the next word directly.\n",
    "# - Instead, it outputs a probability distribution over the entire vocabulary.\n",
    "#   (e.g., \"around\" gets high probability, \"airplane\" gets low probability).\n",
    "#\n",
    "# Model design:\n",
    "# 1. The transformer modifies each word’s vector so it carries context.\n",
    "#    (\"ran\" knows it refers to \"dog\").\n",
    "# 2. The output head (the last layer) uses this contextualized vector\n",
    "#    to produce probabilities over the vocabulary.\n",
    "# 3. If the model is trained well:\n",
    "#    - Words that make sense in context get high probability (e.g., \"around\").\n",
    "#    - Words that don’t fit the context get low probability (e.g., \"airplane\").\n",
    "\n",
    "\n",
    "# The embedding vector represents the semantic meaning of a word.\n",
    "#\n",
    "# The key vector encodes what contextual information a word can provide to others.\n",
    "# Example: the key vector of \"dog\" contains information that could be useful\n",
    "# for words like \"quickly\" or \"ran\".\n",
    "#\n",
    "# The query vector encodes what type of context a word is looking for.\n",
    "# Example: the query of \"quickly\" asks questions like:\n",
    "#   - \"Who is acting?\" \n",
    "#   - \"What action is happening?\"\n",
    "#\n",
    "# Attention works by comparing queries against keys:\n",
    "# - Query(\"quickly\") is compared to Key(\"dog\"), Key(\"ran\"), etc.\n",
    "# - If the model is well trained, the query of \"quickly\" will strongly match\n",
    "#   with the keys of \"ran\" and \"dog\", since those provide the most relevant context.\n",
    "#\n",
    "# In summary:\n",
    "# - Embedding → meaning of the word itself.\n",
    "# - Key       → what context a word can provide.\n",
    "# - Query     → what context a word is seeking.\n",
    "\n",
    "# Attention mechanism: step by step\n",
    "#\n",
    "# 1) Compute raw scores:\n",
    "#    - For each query, take the dot product with every key.\n",
    "#    - This produces the *attention score matrix* (unnormalized).\n",
    "#\n",
    "# Example sentence: \"life is short eat dessert first\"\n",
    "#\n",
    "# Raw attention scores (simplified, arbitrary numbers for illustration):\n",
    "#\n",
    "#           life   is   short   eat   dessert   first\n",
    "# life      2.0   1.5    1.2    0.8     0.3      0.1\n",
    "# is        1.0   2.5    1.7    0.6     0.4      0.2\n",
    "# short     0.9   1.1    2.8    1.0     0.7      0.3\n",
    "# eat       0.4   0.5    0.9    2.2     1.5      0.8\n",
    "# dessert   0.3   0.4    0.6    1.0     2.6      1.9\n",
    "# first     0.2   0.3    0.5    0.8     1.2      2.7\n",
    "#\n",
    "# 2) Scale scores:\n",
    "#    - Divide each dot product by √d (d = dimension of keys/queries).\n",
    "#    - This prevents very large values when d is large.\n",
    "#\n",
    "# Scaled attention scores (still before masking):\n",
    "#\n",
    "#           life   is   short   eat   dessert   first\n",
    "# life      0.5   0.4    0.3    0.2     0.1      0.0\n",
    "# is        0.2   0.6    0.4    0.1     0.1      0.0\n",
    "# short     0.2   0.3    0.7    0.2     0.2      0.1\n",
    "# eat       0.1   0.1    0.2    0.6     0.4      0.2\n",
    "# dessert   0.1   0.1    0.2    0.2     0.7      0.5\n",
    "# first     0.0   0.1    0.1    0.2     0.3      0.7\n",
    "#\n",
    "# 3) Apply causal masking:\n",
    "#    - For each query word, block attention to *future* tokens by setting those\n",
    "#      scores to -∞ (which softmax will later turn into 0).\n",
    "#\n",
    "# Example after masking (values to the right of the diagonal are set to -∞):\n",
    "#\n",
    "#           life    is   short   eat   dessert   first\n",
    "# life      0.5   -∞     -∞      -∞      -∞       -∞\n",
    "# is        0.2    0.6   -∞      -∞      -∞       -∞\n",
    "# short     0.2    0.3    0.7    -∞      -∞       -∞\n",
    "# eat       0.1    0.1    0.2     0.6    -∞       -∞\n",
    "# dessert   0.1    0.1    0.2     0.2     0.7     -∞\n",
    "# first     0.0    0.1    0.1     0.2     0.3      0.7\n",
    "#\n",
    "# 4) Softmax:\n",
    "#    - Apply softmax row by row to turn scores into probabilities.\n",
    "#    - Probabilities sum to 1 for each query.\n",
    "#    - Future tokens get exact probability 0 (thanks to masking).\n",
    "#\n",
    "# Final attention matrix (probabilities):\n",
    "#\n",
    "#           life    is   short   eat   dessert   first\n",
    "# life      1.0   0.0    0.0     0.0     0.0      0.0\n",
    "# is        0.3   0.7    0.0     0.0     0.0      0.0\n",
    "# short     0.3   0.1    0.6     0.0     0.0      0.0\n",
    "# eat       0.2   0.2    0.2     0.4     0.0      0.0\n",
    "# dessert   0.1   0.1    0.2     0.2     0.4      0.0\n",
    "# first     0.1   0.1    0.2     0.2     0.2      0.2\n",
    "#\n",
    "# Interpretation:\n",
    "# - Row = query word asking for context.\n",
    "# - Column = key word providing context.\n",
    "# - Values = probability of how much attention is given.\n",
    "# - Example: \"is\" attends 30% to \"life\" and 70% to itself.\n",
    "\n",
    "\n",
    "# and now we create a new vector is called value its what we gonna add \n",
    "# the ittuition of it what you should get from me to encode my context \n",
    "# value (dog) it encoded the context of dog it give \n",
    "# key (dog) [0.54, 0.36, 0.74]\n",
    "# value (dog) [0.12, 0.84, 0.51]\n",
    "# query (quickly) [0.22, 0.64, 0.73]\n",
    "# value (quickly) [0.62 ,0.24, 0.33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fe00899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query vs Key vs Value\n",
    "# 1. Query (Q)\n",
    "# Question: \"What context do I need?\"\n",
    "# Example: \"quickly\" → its query says:\n",
    "#   \"I need to know who performed the action and what action happened.\"\n",
    "#\n",
    "# 2. Key (K)\n",
    "# Answer: \"What context can I provide?\"\n",
    "# Example: \"dog\" → its key says:\n",
    "#   \"I can provide information that I am the subject.\"\n",
    "# Example: \"ran\" → its key says:\n",
    "#   \"I can provide information that I am the main action.\"\n",
    "#\n",
    "# Queries are compared against keys to decide which tokens to attend to.\n",
    "#\n",
    "# 3. Value (V)\n",
    "# Once you know which token to look at (via keys), what you actually receive is the value.\n",
    "# The value is the real content that a word contributes to the others.\n",
    "#\n",
    "# Examples:\n",
    "# - \"dog\": its value contains \"animal, subject, singular\".\n",
    "# - \"ran\": its value contains \"past action, verb of movement\".\n",
    "#\n",
    "# Intuition:\n",
    "# - Key = the doorbell (identity: \"I’m here\").\n",
    "# - Value = the package you receive when you open the door.\n",
    "# The query rings many doorbells (keys), and based on attention weights,\n",
    "# it collects a weighted mix of the values.\n",
    "#\n",
    "# Quick summary:\n",
    "# - Query → what I am looking for.\n",
    "# - Key   → how I identify myself so others can find me.\n",
    "# - Value → what I give if someone attends to me.\n",
    "#\n",
    "# --- Mini dialogue example with the sentence: \"The dog ran quickly\" ---\n",
    "#\n",
    "# \"quickly\" (Query):\n",
    "#   → \"I need context… who did the action and what action was it?\"\n",
    "#\n",
    "# \"dog\" (Key):\n",
    "#   → \"I can tell you that I am the subject.\"\n",
    "#\n",
    "# \"dog\" (Value):\n",
    "#   → \"Here’s my content: subject = dog, singular, actor of the action.\"\n",
    "#\n",
    "# \"ran\" (Key):\n",
    "#   → \"I can tell you I’m the verb of movement, in past tense.\"\n",
    "#\n",
    "# \"ran\" (Value):\n",
    "#   → \"Here’s my content: action = run, tense = past.\"\n",
    "#\n",
    "# \"quickly\" (receiving Values):\n",
    "#   → \"Okay, with the Values I got from ‘dog’ and ‘ran’, now I know this means:\n",
    "#       ‘the dog ran quickly’.\"\n",
    "#\n",
    "# Final intuition:\n",
    "# - Query → question (\"what context do I need?\")\n",
    "# - Key   → identity (\"what context can I provide?\")\n",
    "# - Value → package (\"the actual information I contribute\").\n",
    "\n",
    "# In self-attention:\n",
    "# - For each token, the query is compared with the keys of other tokens.\n",
    "# - This produces attention weights (probabilities).\n",
    "# - Using these weights, a weighted combination of the values from the attended tokens is created.\n",
    "# - The resulting context vector is then combined with the token’s original embedding\n",
    "#   (via residual connection and normalization) to form the new representation of that token.\n",
    "\n",
    "# After computing Q, K, and V for each word, we pass their outputs through a\n",
    "# separate neural network called a feed-forward layer.\n",
    "# - This layer can be a simple MLP or something more advanced like a mixture of experts.\n",
    "# - It applies a nonlinear activation function, which reshapes the information.\n",
    "# Intuition:\n",
    "# Attention may mix in some irrelevant context. The feed-forward layer acts like\n",
    "# a filter: it strengthens important features and reduces noise or less useful context,\n",
    "# making the representation of each word more meaningful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c4398ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let see how Q, K, and V are created \n",
    "# For each token embedding \"e\", we create three new vectors:\n",
    "#   q = e @ Wq\n",
    "#   k = e @ Wk\n",
    "#   v = e @ Wv\n",
    "# Here Wq, Wk, Wv are weight matrices learned during training.\n",
    "#\n",
    "# 3) Are Wq, Wk, Wv always the same?\n",
    "# - They are the same for all tokens within one attention head of one layer\n",
    "#   (shared weights across tokens).\n",
    "# - They are different for each head and each transformer layer.\n",
    "# - During training, their values change as they are optimized. \n",
    "#   After training, they stay fixed.\n",
    "# Important:\n",
    "# - The \"dot product\" between Q and K happens later, when calculating attention scores.\n",
    "# - The creation of Q, K, V is just a linear projection using the learned matrices.\n",
    "\n",
    "\n",
    "# --- Understanding matrix multiplication vs. dot product in Attention ---\n",
    "#\n",
    "# 1) Creating Q, K, V:\n",
    "# - Each token has its embedding vector, e.g. dog = [0.5, 0.1, 0.3].\n",
    "# - To get Q, K, V we multiply the embedding with Wq, Wk, Wv:\n",
    "#       Q = E @ Wq\n",
    "#       K = E @ Wk\n",
    "#       V = E @ Wv\n",
    "# - Here E is the matrix of embeddings for all tokens (tokens are rows).\n",
    "# - Matrix multiplication is row × column, so no transpose is needed.\n",
    "# - The result: Q, K, V are also matrices where each row corresponds to one token.\n",
    "# - All tokens are projected at the same time (batch style).\n",
    "#\n",
    "# 2) Computing attention scores (Q @ K^T):\n",
    "# - Now we want to compare every query with every key.\n",
    "# - If we try Q @ K (without transpose), dimensions won’t match and the math doesn’t make sense.\n",
    "# - We need K^T so that each query row can take a dot product with each key row.\n",
    "#   Example: row i of Q compares with row j of K → scalar score.\n",
    "# - This gives us the attention score matrix (tokens × tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be24b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Masking the attention scores (affinity matrix) ---\n",
    "#\n",
    "# After computing the raw attention scores = Q @ K^T, \n",
    "# we get an affinity matrix (one row per query token, one column per key token).\n",
    "#\n",
    "# Example with 4 tokens: \"life is short eat\"\n",
    "#\n",
    "# Raw scores (toy values):\n",
    "#        life   is   short   eat\n",
    "# life    2.0   1.5   1.2    0.8\n",
    "# is      1.0   2.5   1.7    0.6\n",
    "# short   0.9   1.1   2.8    1.0\n",
    "# eat     0.4   0.5   0.9    2.2\n",
    "#\n",
    "# --- Why masking? ---\n",
    "# In causal/decoder attention, a token should NOT look into the future.\n",
    "# Example: \"life\" cannot attend to \"is\", \"short\", \"eat\".\n",
    "#\n",
    "# So we set all positions to the right of the diagonal = -∞ (very negative).\n",
    "#\n",
    "# Masked scores:\n",
    "#        life    is   short   eat\n",
    "# life    2.0   -∞     -∞     -∞\n",
    "# is      1.0    2.5   -∞     -∞\n",
    "# short   0.9    1.1   2.8    -∞\n",
    "# eat     0.4    0.5   0.9    2.2\n",
    "#\n",
    "# --- Next step ---\n",
    "# After masking, we apply softmax row by row.\n",
    "# -∞ turns into probability 0.\n",
    "# This ensures each token only attends to past or current tokens.\n",
    "\n",
    "# Attention row for \"quickly\" = [0.1, 0.7, 0.2]\n",
    "# Values = [V(dog), V(ran), V(quickly)]\n",
    "#\n",
    "# New \"quickly\" = 0.1*V(dog) + 0.7*V(ran) + 0.2*V(quickly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- From embeddings to Q, K, V (per head) ---\n",
    "# Let E be the embedding matrix of the sequence, with tokens as rows:\n",
    "#   E ∈ [num_tokens x d_model]\n",
    "# For one attention head with head size d_head, we use learned weight matrices:\n",
    "#   Wq ∈ [d_model x d_head], Wk ∈ [d_model x d_head], Wv ∈ [d_model x d_head]\n",
    "# We obtain Q, K, V by matrix multiplication (no transpose needed here):\n",
    "#   Q = E @ Wq    # Q ∈ [num_tokens x d_head]\n",
    "#   K = E @ Wk    # K ∈ [num_tokens x d_head]\n",
    "#   V = E @ Wv    # V ∈ [num_tokens x d_head]\n",
    "# Each row of Q/K/V corresponds to one token (the projection of that token’s embedding).\n",
    "\n",
    "# --- What is out_head for a token? ---\n",
    "# For one attention head and one token (e.g. \"quickly\"):\n",
    "#   out_head(quickly) = [attention row of \"quickly\"] @ V\n",
    "#\n",
    "# Example:\n",
    "#   Attention row for \"quickly\" = [0.1, 0.7, 0.2]\n",
    "#   V = [V(dog), V(ran), V(quickly)]\n",
    "#   => out_head(quickly) = 0.1*V(dog) + 0.7*V(ran) + 0.2*V(quickly)\n",
    "\n",
    "# --- Where does the attention row come from? ---\n",
    "# Attention matrix = softmax( (Q @ K^T) / sqrt(d_head) )\n",
    "# - Each row = probabilities of how much one token attends to all others.\n",
    "# - Row i corresponds to token i (e.g., \"quickly\").\n",
    "\n",
    "# --- Full head output (all tokens at once) ---\n",
    "# Out_head = Attention @ V\n",
    "# Shapes:\n",
    "#   Attention: [num_tokens x num_tokens]\n",
    "#   V:         [num_tokens x d_head]\n",
    "#   Out_head:  [num_tokens x d_head]\n",
    "\n",
    "# --- Multi-head attention ---\n",
    "# - Each head produces its own Out_head (a different \"view\" of context).\n",
    "# - Concatenate along the feature dimension:\n",
    "#     concat(out_head_1, ..., out_head_H) → [num_tokens x (H * d_head)] = [num_tokens x d_model]\n",
    "# - Apply final linear projection:\n",
    "#     Out = concat(...) @ W_o  → [num_tokens x d_model]\n",
    "\n",
    "# --- Important ---\n",
    "# - Q, K, V are intermediate projections used to compute Attention.\n",
    "# - They are NOT concatenated; what we concatenate are the per-head outputs (Out_head)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2aa753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- After multi-head: concatenate and project with output matrix ---\n",
    "#\n",
    "# Important correction:\n",
    "# - We do NOT concatenate the Value matrices themselves.\n",
    "# - We concatenate the per-head OUTPUTS (the context vectors), i.e., Out_head from each head.\n",
    "#\n",
    "# Steps:\n",
    "# 1) For each head h:\n",
    "#      Attention_h = softmax(Q_h @ K_h.T / sqrt(d_head))\n",
    "#      Out_head_h  = Attention_h @ V_h        # shape: [T x d_head]\n",
    "#\n",
    "# 2) Concatenate all head outputs along the feature dimension:\n",
    "#      Out_concat = concat(Out_head_1, ..., Out_head_H)  # shape: [T x (H * d_head)] = [T x d_model]\n",
    "#\n",
    "# 3) Apply the output projection (the \"output conversion\" matrix W_o):\n",
    "#      Final = Out_concat @ W_o   # W_o ∈ [d_model x d_model], so Final ∈ [T x d_model]\n",
    "#\n",
    "# Intuition:\n",
    "# - Each head gives a different slice of context.\n",
    "# - Concatenation gathers all slices.\n",
    "# - W_o mixes them back into the model’s main representation size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b736cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Output projection (Wo) after multi-head attention ---\n",
    "#\n",
    "# 1) After multi-head attention we concatenate all head outputs:\n",
    "#      Out_concat ∈ [num_tokens x (H * d_head)] = [num_tokens x d_model]\n",
    "#    - Each head gives part of the context.\n",
    "#    - Concatenation just places them side by side.\n",
    "#\n",
    "# 2) To mix these pieces together, we apply the output projection matrix Wo:\n",
    "#      Final = Out_concat @ Wo\n",
    "#    - Wo ∈ [d_model x d_model]\n",
    "#    - The result has the same size as the original embeddings: [num_tokens x d_model]\n",
    "#\n",
    "# 3) Where does Wo come from?\n",
    "#    - Wo is a learned weight matrix, just like Wq, Wk, Wv.\n",
    "#    - It is trained with backpropagation together with the rest of the model.\n",
    "#\n",
    "# Intuition:\n",
    "# - Concatenation = collect context from all heads.\n",
    "# - Wo = learn how to combine them into one coherent vector per token,\n",
    "#   so the model can continue with the next layers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
